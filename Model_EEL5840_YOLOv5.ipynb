{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "01c518a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset, Dataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode\n",
    "#https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "dc7e294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.25\n",
    "\n",
    "dataset = np.load('data_train.npy').reshape((300, 300, 9032))\n",
    "labels = np.load('t_train_corrected.npy')\n",
    "if os.path.exists(\"train\"):\n",
    "    shutil.rmtree(\"train\")\n",
    "if os.path.exists(\"test\"):\n",
    "    shutil.rmtree(\"test\")\n",
    "os.mkdir(\"train\")\n",
    "os.mkdir(\"test\")\n",
    "os.mkdir(\"train/images\")\n",
    "os.mkdir(\"train/labels\")\n",
    "os.mkdir(\"test/images\")\n",
    "os.mkdir(\"test/labels\")\n",
    "\n",
    "train_indices, test_indices = train_test_split(range(9032), test_size=test_size, shuffle=False)\n",
    "\n",
    "for i in range(10):\n",
    "    for idx in np.where(labels[train_indices] == i)[0]:\n",
    "        image = Image.fromarray(dataset[:, :, idx], mode = 'L').convert(\"RGB\").resize((320, 320))\n",
    "        image.save(\"train/images/\" + str(i) + \"_\" + str(idx) + \".jpg\")\n",
    "        with open(\"train/labels/\" + str(i) + \"_\" + str(idx) + \".txt\", \"w\") as f:\n",
    "            f.write(str(i) + \" 0.5 0.5 1 1\")\n",
    "    for idx in np.where(labels[test_indices] == i)[0]:\n",
    "        image = Image.fromarray(dataset[:, :, idx + len(train_indices)], mode = 'L').convert(\"RGB\").resize((320, 320))\n",
    "        image.save(\"test/images/\" + str(i) + \"_\" + str(idx + len(train_indices)) + \".jpg\")\n",
    "        with open(\"test/labels/\" + str(i) + \"_\" + str(idx + len(train_indices)) + \".txt\", \"w\") as f:\n",
    "            f.write(str(i) + \" 0.5 0.5 1 1\")\n",
    "            \n",
    "for idx in np.where(labels[train_indices] == -1)[0]:\n",
    "    image = Image.fromarray(dataset[:, :, idx], mode = 'L').convert(\"RGB\").resize((320, 320))\n",
    "    image.save(\"train/images/\" + str(10) + \"_\" + str(idx) + \".jpg\")\n",
    "    with open(\"train/labels/\" + str(10) + \"_\" + str(idx) + \".txt\", \"w\") as f:\n",
    "        f.write(str(10) + \" 0.5 0.5 1 1\")\n",
    "for idx in np.where(labels[test_indices] == -1)[0]:\n",
    "    image = Image.fromarray(dataset[:, :, idx + len(train_indices)], mode = 'L').convert(\"RGB\").resize((320, 320))\n",
    "    image.save(\"test/images/\" + str(10) + \"_\" + str(idx + len(train_indices)) + \".jpg\")\n",
    "    with open(\"test/labels/\" + str(10) + \"_\" + str(idx + len(train_indices)) + \".txt\", \"w\") as f:\n",
    "        f.write(str(10) + \" 0.5 0.5 1 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a38cac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, criterion, optimizer, scheduler):\n",
    "    since = time.time()\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dataloader_test:\n",
    "        labels = labels.type(torch.LongTensor) \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        outputs.print()\n",
    "        #_, preds = torch.max(outputs, 1)\n",
    "        #print(preds)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    loss = running_loss / dataset_test_size\n",
    "    acc = running_corrects.double() / dataset_test_size\n",
    "\n",
    "    print(f'Loss: {loss:.4f} Acc: {acc:.4f}')\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Testing complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "17b3a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomSymbolImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, img_labels, img_root):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = img_labels\n",
    "        self.img_root = img_root\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_root, self.img_dir[idx])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "15d11223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\justin.rossiter/.cache\\torch\\hub\\master.zip\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirements \"gitpython\" \"tqdm>=4.64.0\" not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  Command 'pip install \"gitpython\" \"tqdm>=4.64.0\"  ' returned non-zero exit status 1.\n",
      "YOLOv5  2022-11-27 Python-3.8.8 torch-1.9.0+cu111 CUDA:0 (NVIDIA GeForce RTX 3090, 24576MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7039792 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "test_root = \"test/images\"\n",
    "test_labels = np.array([int(img[0]) if img[1] != '_' else 10 for img in os.listdir(test_root)])\n",
    "test_imgs = os.listdir(test_root)\n",
    "test_dataset = CustomSymbolImageDataset(test_imgs, test_labels, test_root)\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = torch.hub.load('ultralytics/yolov5', 'custom', path='best.pt', force_reload=True)\n",
    "#model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ea2adc14",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'print'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-194-7d8efbe9c09a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Decay LR by a factor of 0.1 every 7 epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-187-ea5873359da3>\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(model, criterion, optimizer, scheduler)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;31m#_, preds = torch.max(outputs, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m#print(preds)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'print'"
     ]
    }
   ],
   "source": [
    "dataloader_test = DataLoader(test_dataset, batch_size = 4, shuffle = True, num_workers = 0)\n",
    "dataset_test_size = len(test_dataset)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "test_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0c27d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
