{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c518a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode\n",
    "#https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7e294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "test_size = 0.25\n",
    "\n",
    "data_train = np.load('data_train.npy').reshape((300, 300, 9032))\n",
    "data_train = np.repeat(np.expand_dims(data_train, axis = 2), 3, axis=2).T\n",
    "labels_train = np.load('t_train.npy')\n",
    "\n",
    "tensor_data = torch.Tensor(data_train) # transform to torch tensor\n",
    "tensor_labels = torch.Tensor(labels_train)\n",
    "\n",
    "dataset = TensorDataset(tensor_data, tensor_labels) # create your datset\n",
    "\n",
    "train_indices, test_indices = train_test_split(range(len(dataset)), test_size=test_size, shuffle=True)\n",
    "\n",
    "train_subset = Subset(dataset, train_indices)\n",
    "test_subset = Subset(dataset, test_indices)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16009804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                labels = labels.type(torch.LongTensor) \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "119ccead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, criterion, optimizer, scheduler):\n",
    "    since = time.time()\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in dataloader_test:\n",
    "        labels = labels.type(torch.LongTensor) \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    loss = running_loss / dataset_test_size\n",
    "    acc = running_corrects.double() / dataset_test_size\n",
    "\n",
    "    print(f'Loss: {loss:.4f} Acc: {acc:.4f}')\n",
    "\n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Testing complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5322562",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8328743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8320 Acc: 0.7469\n",
      "val Loss: 0.5955 Acc: 0.8260\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4269 Acc: 0.8811\n",
      "val Loss: 0.3523 Acc: 0.9174\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.3160 Acc: 0.9122\n",
      "val Loss: 0.3885 Acc: 0.9159\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.2510 Acc: 0.9286\n",
      "val Loss: 0.3526 Acc: 0.9351\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.1948 Acc: 0.9449\n",
      "val Loss: 0.3007 Acc: 0.9381\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.1549 Acc: 0.9532\n",
      "val Loss: 0.3340 Acc: 0.9322\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.1147 Acc: 0.9672\n",
      "val Loss: 0.2890 Acc: 0.9425\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0601 Acc: 0.9831\n",
      "val Loss: 0.2797 Acc: 0.9454\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0477 Acc: 0.9872\n",
      "val Loss: 0.2739 Acc: 0.9469\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0473 Acc: 0.9902\n",
      "val Loss: 0.2826 Acc: 0.9469\n",
      "\n",
      "Training complete in 5m 53s\n",
      "Best val Acc: 0.946903\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0717 Acc: 0.9838\n",
      "val Loss: 0.0188 Acc: 0.9956\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0597 Acc: 0.9870\n",
      "val Loss: 0.0192 Acc: 0.9956\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0597 Acc: 0.9852\n",
      "val Loss: 0.0168 Acc: 0.9956\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0474 Acc: 0.9897\n",
      "val Loss: 0.0181 Acc: 0.9956\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0459 Acc: 0.9900\n",
      "val Loss: 0.0188 Acc: 0.9956\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0431 Acc: 0.9908\n",
      "val Loss: 0.0180 Acc: 0.9956\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0488 Acc: 0.9888\n",
      "val Loss: 0.0172 Acc: 0.9956\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0441 Acc: 0.9903\n",
      "val Loss: 0.0167 Acc: 0.9956\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0452 Acc: 0.9887\n",
      "val Loss: 0.0190 Acc: 0.9956\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0508 Acc: 0.9892\n",
      "val Loss: 0.0167 Acc: 0.9956\n",
      "\n",
      "Training complete in 5m 49s\n",
      "Best val Acc: 0.995575\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0632 Acc: 0.9857\n",
      "val Loss: 0.0157 Acc: 1.0000\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0557 Acc: 0.9870\n",
      "val Loss: 0.0133 Acc: 1.0000\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0648 Acc: 0.9865\n",
      "val Loss: 0.0163 Acc: 1.0000\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0601 Acc: 0.9856\n",
      "val Loss: 0.0160 Acc: 1.0000\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0604 Acc: 0.9856\n",
      "val Loss: 0.0174 Acc: 1.0000\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0611 Acc: 0.9857\n",
      "val Loss: 0.0145 Acc: 1.0000\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0636 Acc: 0.9854\n",
      "val Loss: 0.0155 Acc: 1.0000\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0599 Acc: 0.9857\n",
      "val Loss: 0.0155 Acc: 0.9985\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0593 Acc: 0.9867\n",
      "val Loss: 0.0128 Acc: 1.0000\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0655 Acc: 0.9854\n",
      "val Loss: 0.0154 Acc: 1.0000\n",
      "\n",
      "Training complete in 5m 44s\n",
      "Best val Acc: 1.000000\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0628 Acc: 0.9852\n",
      "val Loss: 0.0159 Acc: 1.0000\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0627 Acc: 0.9859\n",
      "val Loss: 0.0145 Acc: 1.0000\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0668 Acc: 0.9859\n",
      "val Loss: 0.0129 Acc: 1.0000\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0605 Acc: 0.9865\n",
      "val Loss: 0.0127 Acc: 1.0000\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0636 Acc: 0.9864\n",
      "val Loss: 0.0109 Acc: 1.0000\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0738 Acc: 0.9824\n",
      "val Loss: 0.0144 Acc: 1.0000\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0674 Acc: 0.9831\n",
      "val Loss: 0.0145 Acc: 0.9985\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0651 Acc: 0.9849\n",
      "val Loss: 0.0162 Acc: 0.9971\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0665 Acc: 0.9856\n",
      "val Loss: 0.0137 Acc: 0.9971\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0622 Acc: 0.9854\n",
      "val Loss: 0.0126 Acc: 0.9985\n",
      "\n",
      "Training complete in 5m 41s\n",
      "Best val Acc: 1.000000\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0636 Acc: 0.9857\n",
      "val Loss: 0.0172 Acc: 0.9956\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0638 Acc: 0.9856\n",
      "val Loss: 0.0160 Acc: 0.9970\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0578 Acc: 0.9870\n",
      "val Loss: 0.0156 Acc: 0.9970\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0626 Acc: 0.9851\n",
      "val Loss: 0.0144 Acc: 0.9970\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0610 Acc: 0.9864\n",
      "val Loss: 0.0169 Acc: 0.9956\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0573 Acc: 0.9880\n",
      "val Loss: 0.0163 Acc: 0.9970\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0652 Acc: 0.9844\n",
      "val Loss: 0.0156 Acc: 0.9970\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0644 Acc: 0.9870\n",
      "val Loss: 0.0130 Acc: 0.9970\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0623 Acc: 0.9859\n",
      "val Loss: 0.0171 Acc: 0.9941\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0612 Acc: 0.9861\n",
      "val Loss: 0.0162 Acc: 0.9956\n",
      "\n",
      "Training complete in 5m 44s\n",
      "Best val Acc: 0.997046\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0638 Acc: 0.9867\n",
      "val Loss: 0.0151 Acc: 1.0000\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0619 Acc: 0.9851\n",
      "val Loss: 0.0159 Acc: 1.0000\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0642 Acc: 0.9847\n",
      "val Loss: 0.0171 Acc: 1.0000\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0567 Acc: 0.9867\n",
      "val Loss: 0.0160 Acc: 1.0000\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0629 Acc: 0.9854\n",
      "val Loss: 0.0151 Acc: 1.0000\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0643 Acc: 0.9862\n",
      "val Loss: 0.0140 Acc: 1.0000\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0620 Acc: 0.9864\n",
      "val Loss: 0.0136 Acc: 1.0000\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0634 Acc: 0.9847\n",
      "val Loss: 0.0134 Acc: 1.0000\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0639 Acc: 0.9861\n",
      "val Loss: 0.0148 Acc: 1.0000\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0649 Acc: 0.9859\n",
      "val Loss: 0.0140 Acc: 1.0000\n",
      "\n",
      "Training complete in 5m 43s\n",
      "Best val Acc: 1.000000\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0630 Acc: 0.9867\n",
      "val Loss: 0.0194 Acc: 0.9970\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0623 Acc: 0.9859\n",
      "val Loss: 0.0212 Acc: 0.9956\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0612 Acc: 0.9861\n",
      "val Loss: 0.0168 Acc: 0.9970\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0678 Acc: 0.9854\n",
      "val Loss: 0.0190 Acc: 0.9970\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0586 Acc: 0.9872\n",
      "val Loss: 0.0166 Acc: 0.9970\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0582 Acc: 0.9854\n",
      "val Loss: 0.0178 Acc: 0.9970\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0616 Acc: 0.9869\n",
      "val Loss: 0.0197 Acc: 0.9970\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0632 Acc: 0.9854\n",
      "val Loss: 0.0188 Acc: 0.9970\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0662 Acc: 0.9852\n",
      "val Loss: 0.0189 Acc: 0.9970\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0627 Acc: 0.9869\n",
      "val Loss: 0.0185 Acc: 0.9970\n",
      "\n",
      "Training complete in 5m 44s\n",
      "Best val Acc: 0.997046\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0568 Acc: 0.9870\n",
      "val Loss: 0.0204 Acc: 0.9985\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0724 Acc: 0.9828\n",
      "val Loss: 0.0196 Acc: 0.9985\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0581 Acc: 0.9880\n",
      "val Loss: 0.0202 Acc: 0.9985\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0691 Acc: 0.9849\n",
      "val Loss: 0.0184 Acc: 0.9985\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0601 Acc: 0.9867\n",
      "val Loss: 0.0206 Acc: 0.9970\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0600 Acc: 0.9874\n",
      "val Loss: 0.0219 Acc: 0.9970\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0583 Acc: 0.9852\n",
      "val Loss: 0.0193 Acc: 0.9985\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0600 Acc: 0.9887\n",
      "val Loss: 0.0176 Acc: 0.9985\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0613 Acc: 0.9851\n",
      "val Loss: 0.0206 Acc: 0.9970\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0664 Acc: 0.9859\n",
      "val Loss: 0.0188 Acc: 0.9985\n",
      "\n",
      "Training complete in 5m 39s\n",
      "Best val Acc: 0.998523\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0620 Acc: 0.9880\n",
      "val Loss: 0.0225 Acc: 0.9956\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0625 Acc: 0.9875\n",
      "val Loss: 0.0245 Acc: 0.9956\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0614 Acc: 0.9870\n",
      "val Loss: 0.0249 Acc: 0.9970\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0570 Acc: 0.9875\n",
      "val Loss: 0.0218 Acc: 0.9970\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0696 Acc: 0.9844\n",
      "val Loss: 0.0241 Acc: 0.9970\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0630 Acc: 0.9867\n",
      "val Loss: 0.0204 Acc: 0.9970\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0626 Acc: 0.9864\n",
      "val Loss: 0.0228 Acc: 0.9956\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0687 Acc: 0.9854\n",
      "val Loss: 0.0243 Acc: 0.9970\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0686 Acc: 0.9851\n",
      "val Loss: 0.0195 Acc: 0.9956\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0589 Acc: 0.9864\n",
      "val Loss: 0.0225 Acc: 0.9970\n",
      "\n",
      "Training complete in 5m 35s\n",
      "Best val Acc: 0.997046\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0645 Acc: 0.9846\n",
      "val Loss: 0.0209 Acc: 0.9941\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0579 Acc: 0.9867\n",
      "val Loss: 0.0221 Acc: 0.9970\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0580 Acc: 0.9866\n",
      "val Loss: 0.0194 Acc: 0.9985\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0610 Acc: 0.9869\n",
      "val Loss: 0.0202 Acc: 0.9970\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0620 Acc: 0.9851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0191 Acc: 0.9985\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0575 Acc: 0.9880\n",
      "val Loss: 0.0204 Acc: 0.9970\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0592 Acc: 0.9879\n",
      "val Loss: 0.0182 Acc: 0.9970\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0658 Acc: 0.9846\n",
      "val Loss: 0.0181 Acc: 0.9985\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0606 Acc: 0.9864\n",
      "val Loss: 0.0214 Acc: 0.9970\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0607 Acc: 0.9875\n",
      "val Loss: 0.0188 Acc: 0.9970\n",
      "\n",
      "Training complete in 5m 36s\n",
      "Best val Acc: 0.998523\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "for train_index, val_index in kf.split(train_subset):\n",
    "    train_subset_fold = Subset(train_subset, train_index)\n",
    "    val_subset_fold = Subset(train_subset, val_index)\n",
    "    dataset = {x: train_subset_fold if x == 'train' else val_subset_fold\n",
    "                      for x in ['train', 'val']}\n",
    "\n",
    "    dataloaders = {x: DataLoader(dataset[x], batch_size = 4, shuffle = True, num_workers = 4) for x in ['train', 'val']} # create your dataloader\n",
    "\n",
    "    dataset_sizes = {x: len(dataset[x]) for x in ['train', 'val']}\n",
    "\n",
    "    model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                           num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd59a0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2684 Acc: 0.9429\n",
      "\n",
      "Testing complete in 0m 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_test = DataLoader(test_subset, batch_size = 4, shuffle = True, num_workers = 4)\n",
    "dataset_test_size = len(test_subset)\n",
    "test_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
