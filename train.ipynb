{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a574580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from skimage.filters import threshold_otsu, rank\n",
    "from skimage.morphology import dilation, disk, erosion\n",
    "from skimage import feature\n",
    "import random\n",
    "\n",
    "preceding_path = \"/blue/eel5840/justin.rossiter\"\n",
    "folder_name = \"final_project_team_square_root\"\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "#https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "def generateImageAndLabel(split, i, idx):\n",
    "    image_grayscale = dataset[:, :, idx]\n",
    "    image_bounding = getImageBounding(image_grayscale)\n",
    "    x_mu, y_mu, width, height = getMuAndDimsThroughEdges(image_bounding)\n",
    "    image = Image.fromarray(image_grayscale, mode = 'L').resize((320, 320))\n",
    "    image.save(os.path.join(preceding_path, folder_name, split, \"images\", str(i) + \"_\" + str(idx) + \".jpg\"))\n",
    "    with open(os.path.join(preceding_path, folder_name, split, \"labels\", str(i) + \"_\" + str(idx) + \".txt\"), \"w\") as f:\n",
    "        f.write(str(i) + \" \" + str(x_mu) + \" \" + str(y_mu) + \" \" + str(width) + \" \" + str(height))\n",
    "        \n",
    "def generateAugmentedData(iteration, split):\n",
    "    size = random.randint(2, 4)\n",
    "    image = Image.new('L', (size*300, 300))\n",
    "    i_arr = np.zeros((size, ))\n",
    "    x_mu_arr = np.zeros((size, ))\n",
    "    y_mu_arr = np.zeros((size, ))\n",
    "    width_arr = np.zeros((size, ))\n",
    "    height_arr = np.zeros((size, ))\n",
    "    for i in range(size):\n",
    "        if split == \"train\":\n",
    "            idx = random.randint(0, len(train_indices) - 1)\n",
    "            idx = train_indices[idx]\n",
    "        elif split == \"val\":\n",
    "            idx = random.randint(0, len(val_indices) - 1)\n",
    "            idx = val_indices[idx]\n",
    "        image_temp_arr = dataset[:, :, idx]\n",
    "        image_temp = Image.fromarray(image_temp_arr, mode = 'L')\n",
    "        image.paste(image_temp, (i*300, 0))\n",
    "        i_arr[i] = labels[idx]\n",
    "        if i_arr[i] == -1:\n",
    "            i_arr[i] = 10\n",
    "        image_bounding = getImageBounding(image_temp_arr)\n",
    "        left_edge, right_edge, top_edge, bottom_edge = getEdges(image_bounding)\n",
    "        left_edge += 300*i\n",
    "        right_edge += 300*i\n",
    "        x_mu, y_mu, width, height = getMuAndDims(left_edge, right_edge, top_edge, bottom_edge, 300*size, 300)\n",
    "        x_mu_arr[i] = x_mu\n",
    "        y_mu_arr[i] = y_mu\n",
    "        width_arr[i] = width\n",
    "        height_arr[i] = height\n",
    "    image.save(os.path.join(preceding_path, folder_name, split, \"images\", \"augmented_\" + str(iteration) + \".jpg\"))\n",
    "    with open(os.path.join(preceding_path, folder_name, split, \"labels\", \"augmented_\" + str(iteration) + \".txt\"), \"w\") as f:\n",
    "        for idx in range(size):\n",
    "            f.write(str(i_arr[idx]) + \" \" + str(x_mu_arr[idx]) + \" \" + str(y_mu_arr[idx]) + \" \" + str(width_arr[idx]) + \" \" + str(height_arr[idx]) + \"\\n\")\n",
    "        \n",
    "def getImageBounding(image_grayscale):\n",
    "    radius = 15 #Otsu thresholding\n",
    "    footprint = disk(radius)\n",
    "    threshold_global_otsu = threshold_otsu(image_grayscale)\n",
    "    global_otsu = image_grayscale >= threshold_global_otsu\n",
    "    image_dilated = dilation(global_otsu) #Dilation\n",
    "    image_erosion = erosion(image_dilated) #Image Erosion\n",
    "    image_bounding = 1-image_erosion\n",
    "    return image_bounding\n",
    "        \n",
    "def getMuAndDimsThroughEdges(image_bounding):\n",
    "    left_edge, right_edge, top_edge, bottom_edge = getEdges(image_bounding)\n",
    "    width = (right_edge - left_edge)/300.0\n",
    "    height = (bottom_edge - top_edge)/300.0\n",
    "    x_mu = (right_edge + left_edge)/600.0\n",
    "    y_mu = (bottom_edge + top_edge)/600.0\n",
    "    return x_mu, y_mu, width, height\n",
    "\n",
    "def getMuAndDims(left_edge, right_edge, top_edge, bottom_edge, img_width, img_height):\n",
    "    width = (right_edge - left_edge)/(img_width)\n",
    "    height = (bottom_edge - top_edge)/(img_height)\n",
    "    x_mu = (right_edge + left_edge)/(2*img_width)\n",
    "    y_mu = (bottom_edge + top_edge)/(2*img_height)\n",
    "    return x_mu, y_mu, width, height\n",
    "\n",
    "def getEdges(image_bounding):\n",
    "    left_edge = np.where(np.array([np.sum(image_bounding[:, i]) for i in range(300)]) > 0)[0]\n",
    "    right_edge = np.where(np.array([np.sum(image_bounding[:, i]) for i in range(300)]) > 0)[0]\n",
    "    top_edge = np.where(np.array([np.sum(image_bounding[i, :]) for i in range(300)]) > 0)[0]\n",
    "    bottom_edge = np.where(np.array([np.sum(image_bounding[i, :]) for i in range(300)]) > 0)[0]\n",
    "    if len(left_edge) > 0:\n",
    "        left_edge = left_edge[0]\n",
    "    else:\n",
    "        left_edge = 0\n",
    "    if len(right_edge) > 0:\n",
    "        right_edge = right_edge[-1]\n",
    "    else:\n",
    "        right_edge = 300\n",
    "    if len(top_edge) > 0:\n",
    "        top_edge = top_edge[0]\n",
    "    else:\n",
    "        top_edge = 0\n",
    "    if len(bottom_edge) > 0:\n",
    "        bottom_edge = bottom_edge[-1]\n",
    "    else:\n",
    "        bottom_edge = 300\n",
    "    return left_edge, right_edge, top_edge, bottom_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b959118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "dataset = np.load(os.path.join(preceding_path, 'data_train.npy'))\n",
    "labels = np.load(os.path.join(preceding_path, 't_train_corrected.npy'))\n",
    "if os.path.exists(os.path.join(preceding_path, folder_name, \"train\")):\n",
    "    shutil.rmtree(os.path.join(preceding_path, folder_name, \"train\"))\n",
    "if os.path.exists(os.path.join(preceding_path, folder_name, \"val\")):\n",
    "    shutil.rmtree(os.path.join(preceding_path, folder_name, \"val\"))\n",
    "os.makedirs(os.path.join(preceding_path, folder_name, \"train\", \"images\"))\n",
    "os.makedirs(os.path.join(preceding_path, folder_name, \"train\", \"labels\"))\n",
    "os.makedirs(os.path.join(preceding_path, folder_name, \"val\", \"images\"))\n",
    "os.makedirs(os.path.join(preceding_path, folder_name, \"val\", \"labels\"))\n",
    "\n",
    "train_indices2, test_indices = train_test_split(range(9032), test_size=test_size, shuffle=True)\n",
    "train_indices, val_indices = train_test_split(train_indices2, test_size=test_size, shuffle=True)\n",
    "\n",
    "np.save('data_test.npy', np.array([dataset[:, idx] for idx in test_indices]).T)\n",
    "np.save('t_test.npy', np.array([labels[idx] for idx in test_indices]))\n",
    "dataset = dataset.reshape((300, 300, 9032))\n",
    "\n",
    "for i in range(10):\n",
    "    for idx in np.where(labels == i)[0]:\n",
    "        if idx in train_indices:\n",
    "            generateImageAndLabel(\"train\", i, idx)\n",
    "        elif idx in val_indices:\n",
    "            generateImageAndLabel(\"val\", i, idx)\n",
    "\n",
    "for idx in np.where(labels == -1)[0]:\n",
    "    if idx in train_indices:\n",
    "        generateImageAndLabel(\"train\", 10, idx)\n",
    "    elif idx in val_indices:\n",
    "        generateImageAndLabel(\"val\", 10, idx)\n",
    "        \n",
    "for i in range(300):\n",
    "    generateAugmentedData(i, \"train\")\n",
    "for i in range(300):\n",
    "    generateAugmentedData(i, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa84ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfrl",
   "language": "python",
   "name": "hfrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
